\documentclass[a4paper]{article}

\usepackage{color} %боја у тексту
\usepackage{url} %могу линкови
\usepackage[T2A]{fontenc} %ћирилица јеј
\usepackage[utf8]{inputenc} %непознати карактери
\usepackage{graphicx} %За слику и можда табелу?
\usepackage[english,serbian]{babel}%просто преводи одмах текст(abstract -> сажетак)

\usepackage[unicode]{hyperref} %као css, линкови се боје
\hypersetup{
    colorlinks,
    citecolor=green,
    filecolor=green,
    linkcolor=blue,
    urlcolor=blue
}
\usepackage{hyperref} %за \nameref, тј. да референца буде текст уместо 1
%мора испод hyperref јер ће другачије error омиљени бити :)

\begin{document}

%Почетна страна / насловна
\begin{titlepage}

\newcommand{\HRule}{\rule{\linewidth}{0.4mm}}%као typedef у c++

\center

\textsc{\LARGE Математички факултет}\\[3cm]

\textsc{\Large Семинарски рад}\\[0.1cm]
\textsc{\large из техничког и научног писања}\\[0.5cm]

\HRule\\[0.4cm]
{\LARGE\bfseries Ефекат ауторитета код АИ система}\\[0.2cm]
\HRule\\[2cm]

\vspace{17\baselineskip}

\begin{minipage}{0.4\textwidth}
\begin{flushleft}
\large
\textit{Студент}\\
Марко Грбић 95/2025
\end{flushleft}
\end{minipage}
\hspace*{1cm}
\begin{minipage}{0.4\textwidth}
\begin{flushright}
\large
\textit{Професор}\\
др Јелена Граовац
\end{flushright}
\end{minipage}

\vfill
{\large Београд, \today}

\end{titlepage}

\tableofcontents
\newpage

\abstract{
Овај семинарски рад анализира ефекат ауторитета код система
вештачке интелигенције (АИ), са фокусом на психолошке,
технолошке и етичке аспекте овог феномена. Посебна пажња
посвећена је утицају ауторитета на поверење корисника,
аутоматизованој пристрасности и ризицима прекомерног ослањања
на АИ системе \cite{chatgpt2026}.
}

\section{Увод}
\label{sec:uvod}

Вештачка интелигенција (АИ) заузима све значајнију улогу у
савременом друштву, од система за препоруке до аутономних возила.
Један од кључних фактора прихватања ових система јесте
перцепција ауторитета, која утиче на степен поверења корисника
у одлуке које АИ доноси \cite{Jovanovic2021,chatgpt2026}.

Ефекат ауторитета (енг. \emph{authority effect}) означава
тенденцију људи да прихвате информације и одлуке извора који се
доживљавају као стручни, легитимни или моћни \cite{Cialdini2009}.

\section{Дефиниција ауторитета код АИ система}
\label{sec:definicija}

Ауторитет у контексту АИ система може се дефинисати као способност
система да утиче на корисничке одлуке кроз перцепцију стручности,
објективности и технолошке супериорности \cite{Jovanovic2021,chatgpt2026}.

За разлику од традиционалних ауторитета, АИ системи не поседују
свест нити моралну одговорност, али се често перципирају као
објективни због математичке и алгоритамске природе свог рада
\cite{chatgpt2026}.

\section{Психолошка основа ефекта ауторитета}
\label{sec:psihologija}

Психолошка основа ефекта ауторитета потиче из области социјалне
психологије. Људи су склони да следе препоруке ауторитативних
извора како би смањили когнитивни напор приликом доношења
одлука \cite{Cialdini2009,chatgpt2026}.

Милграмов експеримент (енг. \emph{Milgram obedience experiment})
показао је да су испитаници спремни да следе ауторитет чак и када
су свесни негативних последица својих поступака \cite{Cialdini2009}.
Сличан образац понашања примећује се и у интеракцији са АИ
системима \cite{chatgpt2026}.

Когнитивне пречице (енг. \emph{heuristics}) омогућавају корисницима
да брзо донесу одлуке, али истовремено повећавају вероватноћу
некритичког прихватања АИ препорука \cite{chatgpt2026}.

Поред Милграмовог експеримента, постоје и савремене студије које показују
да људи често приписују већи ауторитет технологијама које користе
формални или стручни језик. На пример, у експериментима
са АИ четботима, корисници су чешће следили препоруке када су поруке
биле написане стручним тоном, чак и када су алтернативе биле логички
једнако валидне \cite{chatgpt2026}.

Овај феномен указује на потребу пажљивог дизајна интерфејса, јер и
„визуелни ауторитет“ (енг. \emph{visual authority}) може појачати
психолошки ефекат и утицати на доношење одлука корисника
\cite{chatgpt2026}.

\section{Утицај ауторитета на корисничко поверење}
\label{sec:uticaj}

Поверење представља кључни фактор успешне интеракције између
људи и АИ система. Истраживања показују да виши степен
перципираног ауторитета води ка већем поверењу корисника
\cite{Miller2019}.

У контексту четбота и виртуелних асистената, ауторитет се гради
кроз формални језик, конзистентне одговоре и коришћење стручне
терминологије \cite{chatgpt2026}.

Корисничко поверење се такође обликује кроз репутацију система,
доследност препорука и доступност објашњења за одлуке (енг. \emph{explainable AI}).
Системи који нуде објашњења својих одлука повећавају поверење,
али и задржавају критичко мишљење корисника, смањујући ризик од
аутоматизоване пристрасности \cite{chatgpt2026}.

Студије су показале да комбинација формалног језика, визуелних сигнала
и транспарентности може повећати прихватање АИ система, али без
опасности од слепог ослањања \cite{chatgpt2026}. На пример: \[
\int_{0}^{\infty} \frac{e^{-x^2}}{1 + x^4} \, dx 
= \frac{\sqrt{\pi}}{2} \cdot \sum_{n=0}^{\infty} \frac{(-1)^n n!}{(2n)!} 
+ \lim_{x \to 0} \frac{\sin(x)}{x^2}
\] Ова формула је инкоректна, али због повећаног и слепог ослањања према
АИ систему, корисник може поверовати и користити неправилну формулу.

\vspace{0.5cm}

\section{Примери примене ауторитета у АИ системима}
\label{sec:primeri}

\subsection{Аутономна возила}
Аутономна возила представљају екстреман пример примене
ауторитета код АИ система. Корисници често без резерве верују
одлукама система чак и у ризичним ситуацијама \cite{Smith2020}.

\subsection{Четботи и виртуелни асистенти}
Виртуелни асистенти користе ауторитативан стил комуникације како
би повећали поверење корисника, што може довести до смањеног
критичког размишљања \cite{Miller2019,chatgpt2026}.

\vspace{0.5cm}

\section{Аутоматизована пристрасност и ефекат ауторитета}
\label{sec:automationbias}

Аутоматизована пристрасност (енг. \emph{automation bias}) описује
тенденцију корисника да прекомерно верују аутоматизованим
системима \cite{Miller2019,chatgpt2026}.

Овај феномен је посебно изражен код система који функционишу као
„црне кутије” (енг. \emph{black box systems}), где корисници немају
увид у процес доношења одлука \cite{chatgpt2026}.
\newpage

\section{Визуелни приказ ауторитета код АИ система}

\begin{figure}[h!]
\centering
\includegraphics[scale=0.5]{slike/Dizajn_AI_sistema.png}
\label{fig:slika}
\caption{Ауторитативног дизајна АИ система}
\end{figure}

На слици \nameref{fig:slika} приказан је визуелан пример над којим темељима 
се АИ системи праве да би помоћу формалног језика и професионалног дизајна појачали
перцепцију ауторитета.

\begin{table}[h!]
\centering
\caption{Ефекат ауторитета у различитим АИ системима}
\vspace{0.5cm}
\begin{tabular}{|c|c|c|}
\hline
АИ систем & Позитиван ефекат & Ризик \\
\hline
Четбот & Веће поверење & Манипулација \\
Аутономно возило & Безбедност & Прекомерно ослањање \\
Медицински АИ & Брже одлуке & Погрешна дијагноза \\
\hline
\end{tabular}
\label{tab:tabela}
\end{table}

\vspace{0.5cm}
У табели \nameref{tab:tabela} приказани су за шта се АИ углавном користи
као позитивни и ризични аспекти ефекта ауторитета код АИ система.

\section{Етика и регулатива АИ ауторитета}
\label{sec:etika}

Примена ефекта ауторитета у АИ системима поставља низ етичких питања,
посебно у областима где одлуке директно утичу на људски живот и сигурност.
Прекомерни ауторитет може довести до ситуација у којима корисници слепо
прихватају одлуке алгоритама, што је посебно опасно у медицини,
саобраћају и финансијама \cite{Brown2021,chatgpt2026}.

Регулатива, као што је EU AI Act, предвиђа обавезу транспарентности и
јасног истицања ограничења АИ система, како би се минимизовао ризик од
аутоматизоване пристрасности. Додатно, дизајнери и
програмери АИ система сносе моралну и правну одговорност за начине
на које системи утичу на одлуке корисника \cite{chatgpt2026}.

Етика у дизајну ауторитета (енг. \emph{ethical AI design}) захтева
имплементацију контрола, објашњење одлука АИ система и едукацију
крајњих корисника. Ово помаже корисницима да задрже критичко
размишљање и смањује ризик од нежељених последица
\cite{chatgpt2026}.

\section{Закључак}
\label{sec:zakljucak}

Ефекат ауторитета код АИ система значајно утиче на начин на који
корисници перципирају и користе савремене технологије
\cite{chatgpt2026}. Иако ауторитет може повећати ефикасност и
поверење, прекомерно ослањање на АИ носи озбиљне ризике
\cite{Brown2021}.

Због тога је неопходно развијати транспарентне и етички
одговорне АИ системе који јасно комуницирају своја ограничења
\cite{chatgpt2026}.

У будућности, развој АИ система са интегрисаним принципима етике
и регулативе омогућиће балансирање између ауторитета и
одговорности. Кроз транспарентне интерфејсе, едукацију корисника
и јасна ограничења, могуће је задржати ефикасност АИ система
без угрожавања критичког мишљења \cite{chatgpt2026}.

\addcontentsline{toc}{section}{Литература}
\appendix

\begin{thebibliography}{6}

\bibitem{Jovanovic2021}
Јовановић, М. (2021).
\emph{Ауторитет у дизајну вештачких интелигенција}.
Journal of AI Research.

\bibitem{Cialdini2009}
Cialdini, R. (2009).
\emph{Influence: The Psychology of Persuasion}.
Harper Business.

\bibitem{Miller2019}
Miller, M. (2019).
User Trust and Authority in AI-Powered Chatbots.
\emph{Human-Computer Interaction}.

\bibitem{Smith2020}
Smith, J. (2020).
Autonomous Vehicles and User Trust.
\emph{AI and Transportation}.

\bibitem{Brown2021}
Brown, L., Green, S. (2021).
Ethical Implications of AI in Medical Systems.
\emph{AI and Ethics}.

\bibitem{chatgpt2026}
OpenAI.
\emph{ChatGPT – Large Language Model}.
Version GPT-5.2, 2026.

\end{thebibliography}

\end{document}